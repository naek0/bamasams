{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from RGB_Lib import Programing_RGB\n",
    "RGB = Programing_RGB()\n",
    "\n",
    "RGB.Set_An_RGB(0, 0xFF, 0xFF, 0xFF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RGB.Set_All_RGB(0xFF, 0x00, 0x00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetbot import Robot\n",
    "robot = Robot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config_for_baseline import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetbot import Camera\n",
    "camera = Camera. instance (width=300, height=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sign task with ['like', 'apple'] categories defined\n"
     ]
    }
   ],
   "source": [
    "import ipywidgets \n",
    "import torchvision.transforms as transforms \n",
    "from dataset import ImageClassificationDataset\n",
    "\n",
    "TASK = DatasetConfig.TASK\n",
    "CATEGORIES = DatasetConfig. CATEGORIES\n",
    "DATASETS = DatasetConfig.DATASETS\n",
    "\n",
    "TRANSFORMS = transforms. Compose ([\n",
    "    transforms. ColorJitter (0.2, 0.2, 0.2, 0.2), transforms. Resize ( (224, 224)), transforms.ToTensor (),\n",
    "    transforms. Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "datasets = {}\n",
    "for name in DATASETS:\n",
    "    datasets [name] = ImageClassificationDataset (TASK + '_' + name, CATEGORIES, TRANSFORMS)\n",
    "    \n",
    "print (\"{} task with {} categories defined\". format (TASK, CATEGORIES) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-8-b7130bff2c77>, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-8-b7130bff2c77>\"\u001b[0;36m, line \u001b[0;32m13\u001b[0m\n\u001b[0;31m    def load _model(c):\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torchvision.transforms as transforms \n",
    "from jetbot import bgr8_to_jpeg \n",
    "import cv2 \n",
    "import IPython.display \n",
    "import torchvision\n",
    "\n",
    "model = torchvision.models.resnet18 (pretrained=True)\n",
    "\n",
    "model_load_button = ipywidgets.Button(description='load model')\n",
    "model_path_widget = ipywidgets.Text (description='model path', value='my_model.pth')\n",
    "\n",
    "def load _model(c):\n",
    "    model. load_state_dict (torch. load (model_path_widget.value))\n",
    "model_load_button.on_click( load _model)\n",
    "\n",
    "model_widget = ipywidgets. VBox([\n",
    "    model_path_widget,\n",
    "    ipywidgets. HBox( [model_load_button])\n",
    "])\n",
    "\n",
    "# display (model_widget)\n",
    "print(\"model configured and model_widget created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import preprocess\n",
    "\n",
    "while True:\n",
    "    image = camera.value\n",
    "    preprocessed = preprocess (image)\n",
    "    output = model (preprocessed)\n",
    "    output = F.softmax(output, dim=1).detach().cpu().numpy().flatten()\n",
    "    category_index = output.argmax ()\n",
    "    prediction_widget.value = dataset.categories [category_index]\n",
    "    for i, score in enumerate(list(output)):\n",
    "        score_widgets [il. value = score\n",
    "        if score_widgets >= 0.5 :\n",
    "            if prediction [0] [0] ['score'] > confidence threshold:\n",
    "                if prediction [0][0] ['label'] =='apple':\n",
    "                    robot.forward(0.3)\n",
    "                    RGB.Set_All_RGB(OxFF, 0x00, 0x00) \n",
    "                else :\n",
    "                    robot.stop ()\n",
    "            else:\n",
    "                RGB. Set_An_RGB(0, OxFF, OxFF, OxFF)\n",
    "    IPython.display.display(IPython. display. Image (data=bgr8_to_jpeg(image)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
